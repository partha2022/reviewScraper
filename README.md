
# review Scraper

### PROBLEM STAEMENT
In this project we will be using python with beautifulsoup to scrape the review from a particular website.

### DESCRIPTION OVERVIEW
In this project we extract certain features like product name, reviewer name, review heading and review comment.

### TECHNOLOGY USE
Here we will be using  Anaconda Python 3.6 , Beautifulsoup, Webscraping, Flask 

### INSTALLATION
Installation of this project is pretty easy. Please do follow the following steps to create a virtual environment and then install the necessary packages in the following environment.

#### In Pycharm

1. Create a new project.
2. Navigate to the directory of the project
3. Select the option to create a new new virtual environment using conda with python3.6
4. Finally create the project using used resources.
5. After the project has been created, install the necessary packages from requirements.txt file using the command 
    pip install -r requirements.txt

#### In Conda

1. Create a new virtual environment using the command
    conda create -n your_env_name python=3.6
2. Navigate to the project directory.
3. Install the necessary packages from requirements.txt file using the command         
    pip install -r requirements.txt




## Acknowledgements

 - [Awesome Readme Templates](https://awesomeopensource.com/project/elangosundar/awesome-README-templates)
 - [Awesome README](https://github.com/partha2022/reviewScraper/blob/master/README.md)
 - [How to write a Good readme](https://bulldogjob.com/news/449-how-to-write-a-good-readme-for-your-github-project)


## Authors

- [@partha](https://github.com/partha2022)


## Contributing

Contributions are always welcome!

See `contributing.md` for ways to get started.

Please adhere to this project's `code of conduct`.


## Deployment

To deploy this project run

```bash
  heroku login
  heroku create
  git init
  git status
  git add .
  git commit -am "commit by partha"
  git push heroku master

  After deployment, heroku gives you the URL to hit the web API
```


## Features

- Light/dark mode toggle
- Live previews
- Fullscreen mode
- Cross platform


## üöÄ About Me
I'm a full stack Data Scientist...

I'm a Data Engineer/Big Data/Hadoop Developer...


# Hi, I'm Partha! üëã


## üîó Links
[![portfolio](https://img.shields.io/badge/my_portfolio-000?style=for-the-badge&logo=ko-fi&logoColor=white)](https://github.com/partha2022)
[![linkedin](https://img.shields.io/badge/linkedin-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/parthass/)


## Other Common Github Profile Sections
üë©‚Äçüíª I'm currently working on...

üß† I'm currently learning...

üëØ‚Äç‚ôÄÔ∏è I'm looking to collaborate on...

ü§î I'm looking for help with...

üí¨ Ask me about...

üì´ How to reach me...

üòÑ Pronouns...

‚ö°Ô∏è Fun fact...


## üõ† Skills
Python, Spark, Pyspark, Java, Scala, Machine Learning, Deep Learning, Natural Language Processing (NLP), Image Processing/Computer Vision, OpenCV, Numpy, Pandas, Scikit-learn, SciPy, NLTK, Word2Vec, TensorFlow, Keras, PyTorch, Matplotlib, Seaborn, BeautifulSoup, EDA (exploratory data analysis), AWS, Heroku, GIT, Hadoop, HDFS, Hive, Cassandra, Stream sets, SQL, Flask, Web scraping, Control-M, HTML ...


#### INSTALLATION

Install project with pip

```bash
  pip install -r requirements.txt
```
    
#### CONCLUSION

Here we have successfully predict insurance bills with 91% accuracy for a particular customer.


## Tech Stack

**Client:** Python, Flask, Webscraping, Beautifulsoup

**Server:**  Heroku, AWS


## Run Locally

Clone the project

```bash
  git clone https://github.com/partha2022/reviewScraper.git
```

Go to the project directory

```bash
  cd reviewScraper
```

Install dependencies

```bash
  pip install -r requirements.txt
```

Start the server

```bash
  python app.py
```


## Running Tests

To run tests, run the following command

```bash
  http://localhost:5000/ 
```

